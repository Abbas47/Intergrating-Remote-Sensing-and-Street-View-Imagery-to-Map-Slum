{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11324286-bdfd-4eed-a324-941f16c0ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Importing libraries\n",
    "# ################################################################\n",
    "import os \n",
    "import zipfile \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c095d-232a-4e09-ac1d-620d63d219e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Define dataset directory\n",
    "# ################################################################\n",
    "dir_ = '/home/jovyan/private/MSc/CNN'\n",
    "base_dir = os.path.join(dir_, 'dataset')\n",
    "weight_dir = os.path.join(dir_, 'network')\n",
    "weight_place365 = os.path.join(weight_dir, 'place_365')\n",
    "weight_hybrid1365 = os.path.join(weight_dir, 'hybrid_1365')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validate')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Directory with our training slum pictures\n",
    "train_slum_dir = os.path.join(train_dir, 'slum')\n",
    "\n",
    "# Directory with our training nonslum pictures\n",
    "train_nonslum_dir = os.path.join(train_dir, 'nonslum')\n",
    "\n",
    "# Directory with our validation slum pictures\n",
    "validation_slum_dir = os.path.join(validation_dir, 'slum')\n",
    "\n",
    "# Directory with our validation nonslum pictures\n",
    "validation_nonslum_dir = os.path.join(validation_dir, 'nonslum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936203d9-716b-4663-b027-bde075f552a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Visualize some sample input data\n",
    "# ################################################################\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "import matplotlib.image as mpimg\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "pic_index = 100\n",
    "train_slum_fnames = os.listdir(train_slum_dir)\n",
    "train_nonslum_fnames = os.listdir(train_nonslum_dir)\n",
    "\n",
    "\n",
    "next_slum_pix = [os.path.join(train_slum_dir, fname) \n",
    "                for fname in train_slum_fnames[ pic_index-8:pic_index]]\n",
    "\n",
    "next_nonslum_pix = [os.path.join(train_nonslum_dir, fname) \n",
    "                for fname in train_nonslum_fnames[ pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_slum_pix+next_nonslum_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa1f51-effb-4675-ad15-7e41a2bc5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255, shear_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "# Note that the test data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ad540-d964-4c41-9918-692e93d7a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow training images in batches of 64 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 64, classes = ['slum', 'nonslum'], target_size = (224, 224))\n",
    "\n",
    "# Flow validation images in batches of 64 using validation_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, batch_size = 64, classes = ['slum', 'nonslum'], target_size = (224, 224))\n",
    "\n",
    "# Flow test images in batches of 64 using validation_datagen generator\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, batch_size = 64, classes = ['slum', 'nonslum'], target_size = (224, 224), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a4032-44a8-4437-bab8-8253d6b86b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891e580-682d-40de-bc88-f0a175e8ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_generator)\n",
    "\n",
    "plotImages(imgs)\n",
    "print(labels)\n",
    "\n",
    "# print(np.argmax(labels, axis=-1))\n",
    "# print(train_generator.classes)\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81166464-f8cd-4dcb-a857-60c84d280d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels1 = next(validation_generator)\n",
    "\n",
    "plotImages(imgs)\n",
    "print(labels1)\n",
    "\n",
    "# print(np.argmax(labels1, axis=-1))\n",
    "# print(validation_generator.classes)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5519d8f3-9219-4188-9a67-61d8b15b75a3",
   "metadata": {},
   "source": [
    "#### Setting up the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830f490-ca78-4b78-b051-2ff7ec32fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/private/MSc/CNN/model')\n",
    "from vgg16_places_365 import VGG16_Places365\n",
    "\n",
    "base_model = VGG16_Places365(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'places', pooling = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3acb9b-9b13-4d17-af21-691f2bdf5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the last one\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ef78c-5104-4b73-960e-f3ed6237505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9), loss = 'binary_crossentropy',metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24d3fd-1ad6-4cd0-91bf-8097d2c2a3ca",
   "metadata": {},
   "source": [
    "#### Configration for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1599f-0eda-44d2-9a3a-5b923a498385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(weight_dir, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit(train_generator, validation_data = validation_generator, epochs = 200, steps_per_epoch = 370, validation_steps = 123, verbose = 1,  callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70112187-0e0b-4636-9a7c-9713e51f9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Learning curves\n",
    "#\n",
    "# To verify whether the algorithm is working, we can plot learning\n",
    "# curve.\n",
    "#\n",
    "#   * model accuracy\n",
    "# ################################################################\n",
    "\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54c9ea-e6e8-4fbd-9d07-b096c6e23aab",
   "metadata": {},
   "source": [
    "#### Accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644fa17-b614-45e7-b204-17865bc1eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Evaluation of the test data\n",
    "#\n",
    "# In this step, the previously created test data set is feeded to\n",
    "# the network. The network responds with a prediciton of slum\n",
    "# The resulting data will be used to assess the  accuracy of the \n",
    "# network.\n",
    "# ################################################################\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "saved_model = load_model(weight_path)\n",
    "predictions = saved_model.predict(x=test_generator, steps=len(test_generator), verbose=0)\n",
    "test_ = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987edf33-07fe-4f29-8165-a550ee2126cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "name_dir = []\n",
    "class_name = []\n",
    "for i in range(7904):\n",
    "    index = i\n",
    "    image, label = test_generator._get_batches_of_transformed_samples(np.array([index]))\n",
    "    image_name = test_generator.filenames[index]\n",
    "    name1 = image_name.split('/')\n",
    "    class_name.append(name1[0]) # appeding true class of image to list\n",
    "    name_dir.append(name1[1][:-4]) # appending image name with direction to list \n",
    "    name2 = name1[1].split('_')\n",
    "    name.append(name2[0]) # appending image name to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ad214-52bb-4c01-8512-54b4e6bb3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_final = pd.DataFrame(columns=['image_name','image_dir', 'predicted_class', 'true_class'])\n",
    "df_final['image_name'] = name\n",
    "df_final['image_dir'] = name_dir\n",
    "df_final['predicted_class'] = test_\n",
    "df_final['true_class'] = class_name\n",
    "# pd.set_option('display.max_rows', df_final.shape[0])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4cc2d-e020-4e51-876c-cb5c39f850e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"vgg16_output\"\n",
    "file_path = csv_dir + \"/\" + file_name + \".csv\"\n",
    "df_final.to_csv(file_path, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78f764-e2f1-4190-ad47-7ddd0a037efe",
   "metadata": {},
   "source": [
    "#### Accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc914762-7cd1-4dac-9602-d2171e4c9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Accuracy \n",
    "# ################################################################\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4c6a7-084f-4cd2-8e2f-365e052a5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true=test_generator.classes, y_pred=np.argmax(predictions, axis=-1))\n",
    "cm_plot_labels = ['slum','nonslum']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc71681-aa17-4062-b6fd-1deebbf672fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Accuracy Matrix\n",
    "# ################################################################\n",
    "\n",
    "import pandas\n",
    "from IPython.display import display\n",
    "\n",
    "def print_scores(title, tp, fp, fn, tn):\n",
    "    \"\"\"Calculates and prints the typical precision scores of a machine learning\n",
    "    algorithm.\n",
    "\n",
    "    :param title: Title to be printed\n",
    "    :param tp: number of true positives\n",
    "    :param fp: number of false positives\n",
    "    :param fn: number of false negatives\n",
    "    :param tn: number of true negatives\n",
    "    \"\"\"\n",
    "    total = sum([tp, fp, fn, tn])\n",
    "    # Accuracy\n",
    "    # How many pixels are classified correctly?\n",
    "    accuracy = (tp + tn) / total\n",
    "\n",
    "    # Precision / Specification\n",
    "    # How accurate can the network determine field boundaries?\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    # Recall / Sensitivity\n",
    "    # How many boundaries did we detect out of all actual field boundary pixels?\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    # F1 score\n",
    "    # harmonic mean of recall & precision\n",
    "    f1 = ( 2 * ( precision * recall ) ) / ( precision + recall )\n",
    "    #f1 = 2 * ( ( precision * recall ) / (precision + recall) )\n",
    "\n",
    "\n",
    "    accuracy *= 100\n",
    "    precision *= 100\n",
    "    recall *= 100\n",
    "    f1 *= 100\n",
    "\n",
    "    print(f\"Accuracy Assessment: {title}\")\n",
    "    print(\"=\" * 32)\n",
    "    print(\"{:<32} {:<10} %\".format(\"Overall Accuracy\", round(accuracy, 3)))\n",
    "    print(\"{:<32} {:<10} %\".format(\"Precision\", round(precision, 3)))\n",
    "    print(\"{:<32} {:<10} %\".format(\"Recall\", round(recall, 3)))\n",
    "    print(\"{:<32} {:<10} %\".format(\"F1 Score\", round(f1, 3)))\n",
    "    print(\"\\n\" * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5d4cf-e959-403a-afc8-114459405640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(title = \"Confusion Matrix\",tp = cm[1,1], fp = cm[0,1], fn = cm[1,0], tn = cm[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
